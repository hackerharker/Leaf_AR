# Leaf_AR

This discursive tool seeks to engage people in technologically mediated experiences with nature as climate change fundamentally alters our experience of nature.  Our suppression of forest fires, in conjunction with climate change, has caused these now regular catastrophic seasonal events. It is a self perpetuating cycle as the carbon sequestering/ climate change mitigating power of forests is negated as their biomass burns. The tool enables the user to ‘identify’ burnt tree leaves falling from trees in burning forests.

Using AR on their phone the user can view burnt leaves, which are brown, warped, broken, and sometimes bubbling, falling down around them. People are posting these leaf images on social media, asking people to help identify them, as often they have drifted in with ash from trees burning miles away. In that regard, the project also shows how the distance between trees and people becomes truncated in our shared experiences of poor air quality and falling ash.

Eventually, the tool can evolve to use the user’s geolocated location, data on trees and spatial analysis of fires and use machine learning to provide specific leaf identification suggestions, taking into account specific characteristics of different leaf species when burnt, wind directions, locations of fires, proximity to fires, and data on tree types in the locations where there are fires burning.

The tool seeks to  increase awareness of relationally between ourselves and nature, with the belief that a “change in perception” of our impacts on the environment as the first step in positive futuring.
